# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZaMcsQDYgCu7ttHTnrU10sSrH7zr2NqT

## 讀取資料集
"""

from google.colab import drive
drive.mount('/content/drive')

"""original : (1141340, 23) (380447, 23)
<br>dropNA : (1131935, 32) (377271, 32)
"""

import pandas as pd

train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train_cleaned.csv')
test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test_cleaned.csv')

objList = ['flbmk', 'flg_3dsmk']
for obj in objList:
  test[obj] = (test[obj]=='Y').astype(int)

print(train.shape, test.shape)
print(test.dtypes)

# drop features
train = train.drop(columns=['conam_log', 'conam_stz','txkey'])
test = test.drop(columns=['conam_log', 'conam_stz','txkey'])

print(train.shape, test.shape)
test.columns

# separate X (feature) and y (label) for training data
y_train = train['fraud_ind']
X_train = train.drop(columns=['fraud_ind'])

# separate X (feature) and y (label) for test data
y_test = test['fraud_ind']
X_test = test.drop(columns=['fraud_ind'])

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

"""## SMOTE + RFC"""

# method 1 --> SMOTE
# 對樣本少的類別進行 Oversampling ，使正、反例為 1:1
from imblearn.over_sampling import SMOTE

sm = SMOTE(sampling_strategy='minority', random_state=238)
over_X_train, over_y_train = sm.fit_sample(X_train, y_train)
print()
print("Data size before SMOTE : ", X_train.shape, "Data size after SMOTE : ", over_X_train.shape)

# 模型訓練 - 隨機森林 : Bagging + Decision tree
from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=20, max_depth=4)
rfc.fit(over_X_train, over_y_train)

# 模型測試，輸出結果
from sklearn.metrics import roc_auc_score, classification_report

y_pred_rfc = rfc.predict(X_test)
print('auc:', roc_auc_score(y_test, y_pred_rfc))

print(classification_report(y_test, y_pred_rfc))

# 混淆矩陣視覺化
import seaborn as sns
from sklearn.metrics import plot_confusion_matrix

sns.set_context("poster")

disp = plot_confusion_matrix(rfc, X_test, y_test)
_ = disp.ax_.set_title("Random Forest")

"""## BBC"""

# method 2 --> BalancedBaggingClassifier
# 訓練一個分類器來處理類別不平衡問題，而不必在訓練前手動進行欠採樣或過採樣
# Under-sample the majority class(es) by randomly picking samples with or without replacement.

from imblearn.ensemble import BalancedBaggingClassifier
from sklearn.tree import DecisionTreeClassifier

bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features='auto'),
                                replacement=True,
                                bootstrap_features=True) 
# 訓練測試
bbc.fit(X_train, y_train)

print(X_train.shape, X_test.shape)

# 模型測試，輸出結果
from sklearn.metrics import roc_auc_score
from sklearn.metrics import classification_report

y_pred = bbc.predict(X_test)
print('auc:', roc_auc_score(y_test, y_pred))

print(classification_report(y_test, y_pred))

# 混淆矩陣視覺化
import seaborn as sns
from sklearn.metrics import plot_confusion_matrix

sns.set_context("poster")

disp = plot_confusion_matrix(bbc, X_test, y_test)
_ = disp.ax_.set_title("Balanced Bagging")

"""## 實驗成果視覺化"""

# 混淆矩陣視覺化
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix

titles_options = [#(rfc," SMOTE + Random Forest", 'true'),
                  (bbc,"Balanced Bagging Classifier", 'true')]
for model, title, normalize in titles_options:
    disp = plot_confusion_matrix(model, X_test, y_test,
                                 cmap=plt.cm.Blues,
                                 normalize=normalize)
    disp.ax_.set_title(title)

    print(title)
    print(disp.confusion_matrix)

plt.show()

# 繪製 ROC 曲線
import matplotlib.pyplot as plt
from sklearn import metrics

#metrics.plot_roc_curve(rfc, X_test, y_test)
metrics.plot_roc_curve(bbc, X_test, y_test)
plt.show()

"""## 輸出檔案 --> 錯誤案例分析"""

result = X_test.copy()
print(result.shape)

result['fraud_ind'] = y_test
print(result.shape)

result['predict'] = y_pred
print(result.shape)

result.to_csv('/content/drive/MyDrive/Colab Notebooks/test_withPred.csv',index=False)